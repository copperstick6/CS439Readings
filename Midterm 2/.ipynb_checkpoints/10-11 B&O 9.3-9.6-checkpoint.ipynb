{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9.3 VM as a tool for caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VM is organized as an array of N contiguous byte size cells stored on disk. Each byte has a unique virutal address that serves as an index into the array. The contents of this array is cached into main memory.   \n",
    "VM systems partition the virtual memory into fixed size blocks called virtual pages. Physical memory is partitioned into physical pages.  \n",
    "The set of virtual pages is partitioned into three subsets, unallocated, cached, uncached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.1 DRAM Cache Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS429 stuff. :sick:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.2 Page Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A page table maps virtual pages to physical tables. The address translation hardware reads the page table each time it converts a virtual address to a physical address.  \n",
    "A page table is an array of PTE (page table entries). Each page in the virtual address space has a PTE at a fixed offset in the page table. It has a valid bit, and if it is set, the address field indicates the start of the corresponding physical page where the virtual page is cached, specifically the start of the virtual page on the disk. If it is not set, a null address indicates that the virtual page has not yet been allocated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.3 Page Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the CPU tries to read mapped memory, the address translation hardware uses the virtual address to locate the page table entry and then read the physical memory that it points to. Since the valid bit is set, since it is mapped memroy, the address translation hardware knows that it is cached in memory, so it uses the page table entry to construct the physical address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.4 Page Faults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cache miss is known as a page fault. The CPU has regerenced something that is not cached. The address translation hardware reads the page table entry, and sees that the valid bit is not set, and triggers a page fault exception, and selects a victim page to replace. The kernel copies the virtual page from disk to the physical page in memory, updates the page table entry, and then returns. The handler returns, and the instruction continues, and it now references the virtual page, which is not mapped.   \n",
    "The activity of transferring a page between disk and memory is known as swapping.  \n",
    "The act of swapping a page when a miss occurs is known as demand paging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.5 Allocating Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating new pages of virtual memory is usually done by calling malloc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.6 Locality to the rescue again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual memory mostly because of locality.  \n",
    "Although the total number of distint pages that might be referenced might exceed the size of physical memory, the principle of locality promises that at any point, the program will only use a smaller set of active pages, also known as the working set.  \n",
    "As long as our program has good temporal locality, the virtual memory system will work pretty well. If the working set size exceeds the size of physical memory, the program can experience thrashing, where pages are swapped in continuously. Although VM is usually efficient, if a program's performance starts to slow, maybe it is thrashing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 VM as a tool for memory management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VM simplifies linking and loading, the sharing of code and data, and allocating memory to applications. \n",
    "1. Simplifying linking: A separate address space allows each process to use the same basic format for its memory image.  \n",
    "2. Simplifying Loading: VM makes it easy to load in executable files into memory. The loader can allocate virtual pages for code and data segments of other files, mark them invalid and point their Page table entries to the appropriate locations in the external file.   \n",
    "3. Simplifying sharing: Separate address spaces provide the OS with a mechanism to manage sharing between the user process and OS. Each process has private space not shared with any other process. The OS creates page tables that map the virtual pages to physical pages. In some cases, it is desirable for processes to share code and data. The OS can arrange for multiple processes to share a single copy of code by mapping the pages in different processes to the same physical address.  \n",
    "4. Simplifying memory allocation: Virtual memory provides a simple mechanism for allocating additional memory to user processes. When a program is running, the operating system allocates several aditional pages if needed to the processes. These pages can be scattered throughout physical memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 VM as a tool for memory protection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add additional permission bits to the page table entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Address translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page Hit:\n",
    "1. The processor generates a virtual address and sends it to the MMU\n",
    "2. The MMU generates the page table entry address and requests it from the main memory\n",
    "3. The main memory returns the page table entry to the MMU\n",
    "4. The MMU constructs the physical address and sends it to the cache/main memory\n",
    "5. The cache/main memory returns the data to the processor.   \n",
    "  \n",
    "Page Fault:\n",
    "1. Same as 1-3 for page hit\n",
    "2. The valid bit in the page table entry is zero, so an exception is trigggered, and control is sent to the page fault exception handler in the OS\n",
    "3. The page fault handler identifies the victim page to evict, and if it has been modified, pages it out to disk.  \n",
    "4. The fault handler pages in the new page and updates the page table entry. \n",
    "5. The fault handler returns to the original process, the CPU resends the virtual address to the MMU, but it is a hit this time, since we just mapped it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.1 Integrating Caches and VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most systems go for physical addressing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.2 Speeding up address translation with a TLB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MMU must refer to the PTE in order to translate the virtual address into a physical address every time the CPU generates a virtual address. This requires an addition fetch from memory, which is expensive. However, if it is cached in L1, the cost goes down dramatically. Many systems eliminate this cost by including a cache of PTEs in the MMU called a translation lookaside buffer. It is a virtually addressed cache where each line holds a block consisting of a single page table entry.  \n",
    "1. The CPU generates a virtual address\n",
    "2. The MMU fetches the Page table entry from the avaiable translation lookaside buffer.  \n",
    "3. The MMU translates the virtual address to a physical address and sends it to the cache/main memory\n",
    "4. The cache/main memory returns the requested data to the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.3 Multilevel page tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Slides im not writing this out lmao."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
